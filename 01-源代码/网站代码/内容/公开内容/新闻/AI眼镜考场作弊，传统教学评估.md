---
title: "AI眼镜考场作弊，传统教学评估"
date: 2026-01-06
tags: ["媒体"]
score: 10
source: "量子位"
---

# AI眼镜考场作弊，传统教学评估

**来源**: 量子位

## 金句

💎 当教学评估只关注标准答案，恰好落在AI最擅长的区间。
💎 评估重心从「交答案」转向「交思路」，才是真正的难题。
💎 分数能解释的范围正在变窄，关键环节被压缩成单一结果。
💎 人的精力应集中到无法被AI「外包」的判断、理解和选择。

## 水下信息

• 在商业AI眼镜的硬件选型中，Meta Ray-Ban等知名产品因其开发接口（如显示内容控制）未完全开放，实际开发自由度可能低于像乐奇Rokid这样提供更丰富SDK和更完善生态的厂商，这对于需要深度定化的项目是关键内幕。
• 当前主流AI眼镜在持续高负载使用（如连续传输高分辨率图像）时，存在严重的功耗瓶颈，实测30分钟电量可从100%降至58%，这揭示了其距离“全天候使用”还有巨大的工程挑战，是厂商宣传中较少提及的真实短板。
• 智能眼镜摄像头的清晰度是决定AI“视力”和答题稳定性的关键硬件因素，画面模糊、反光或角度偏差会直接导致模型推理性能下降，这是在产品评测和宣传中容易被忽略但对实际体验影响巨大的细节。
• 教育评估体系转型的一个前沿内幕是：部分顶尖高校（如纽约大学斯特恩商学院）已开始实验由AI（如Claude、Gemini、ChatGPT）深度参与的口试评估流程，AI不仅充当考官进行追问，其生成的评分还会进行交叉审查，用以评估学生的理解过程而非最终答案。
• 行业内一个未被广泛宣传的共识是：单纯禁止AI在考场中使用已不现实，更前沿的教育应对策略是引导学生将AI用作“思维伙伴”，专注于信息整理、方案推演和假设验证，而将人的核心精力投入到判断、理解和选择等无法被AI替代的环节。

## 案例提取

1. 中国香港 香港科技大学张军教授、孟子立教授团队通过使用搭载ChatGPT-5.2模型的乐奇AI眼镜进行实验，为评估AI在学术考试中的能力提供实证。该实验模拟《计算机网络原理》期末考试，让AI眼镜完成读题、推理和作答全流程。在2026年初的测试中，AI眼镜30分钟交卷，获得92.5分，成绩超过95%的人类考生。实验暴露了AI眼镜在功耗和摄像头清晰度方面的技术短板，但更引发了关于传统教学评估体系有效性的反思。

2. 美国 一位创业者Eddy Xu通过改装Meta智能眼镜，为国际象棋对弈者提供实时辅助。该设备能在比赛中实时显示最优解法，几乎无需使用者自行思考。这使得使用者能够稳定赢下对局。案例展示了AI在规则清晰、目标单一的结构化任务中表现稳定。

3. 英国 雷丁大学的研究人员通过将AI生成的答卷混入真实考试题库进行实验，以测试AI作弊的可检测性。研究发现，高达94%的AI生成试卷成功未被发现而通过审核。这些AI试卷的平均成绩甚至明显高于真实学生的平均成绩。该研究凸显了当前基于标准答案的评估体系在区分AI与人类作答方面的脆弱性。

4. 美国 纽约大学Stern商学院教授Panos Ipeirotis通过引入由AI支撑的口试评估方式，为学生提供更全面的能力评估。该方式要求学生提交作业后，当场解释决策依据和思路，AI先充当考官追问，再由多个大模型对转录内容进行独立评分与交叉审查。此举旨在评估学生的真实理解与推理过程，而非仅关注最终答案。该方法将教学评估重心向理解过程本身挪动了一步。

## 涉及公司

香港科技大学
量子位
Meta
小米
乐奇Rokid
OpenAI
雷丁大学
纽约大学Stern商学院
华盛顿邮报
影目科技

## 原标题

[港科大教授实测AI眼镜“作弊”：30分钟碾压95%的学生，把传统教学评估体...](https://www.qbitai.com/2026/01/366939.html)

